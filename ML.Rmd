---
output:
  bookdown::pdf_document2: default
classoption: landscape
---
# Step 4 Machine learning

## Step 0: Look at and Modify the dataset
So, I am curious. Can I predict vaccination data?

```{r python, include=FALSE}
# Setting for using python
library(tidyverse)
library(reticulate)
use_python("/Users/travel_mechtal/opt/anaconda3/bin/python")
use_condaenv("base", required = TRUE)

# if I need a new module
#py_install("ModuleName")
# I already installed: pandas, networkx, typing_extensions, joblib, seaborn, scikit-learn
```

```{python python_libraries, include=FALSE}
# work with dataframes
import pandas as pd
# work with dates
import datetime as dt
# split the dataset
from sklearn.model_selection import train_test_split
# evaluate the model
from sklearn.metrics import mean_absolute_error
# graph data
pd.plotting.register_matplotlib_converters()
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import tree
from sklearn.tree import export_text
# build a model
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
```

```{r ML_r_libraries, include=FALSE}
#---------------------------------------
# ggplot2 -- plot
#---------------------------------------
if(!require(ggplot2)){install.packages("ggplot2")}
library(ggplot2)
#---------------------------------------
# reshape2 -- use melt
#---------------------------------------
if(!require(reshape2)){install.packages("reshape2")}
library(reshape2)
```

```{python read_data, include=FALSE}
# read file
path = "/Users/travel_mechtal/Documents/UWE/Portfolio/"
data=pd.read_csv(path + "region_2022-01-27.csv", index_col="date", parse_dates=True)

# drop unnecessary columns: areaCode, areaName, areaType.
dataset = data.drop(["areaCode", "areaName", "areaType"], axis=1)

# rename columns
# newPeopleVaccinatedFirstDoseByVaccinationDate -> First, 
# newPeopleVaccinatedSecondDoseByVaccinationDate -> Second, 
# newPeopleVaccinatedThirdInjectionByVaccinationDate -> Third
dataset = dataset.rename(columns={"newPeopleVaccinatedFirstDoseByVaccinationDate":"First", 
                                  "newPeopleVaccinatedSecondDoseByVaccinationDate":"Second", 
                                  "newPeopleVaccinatedThirdInjectionByVaccinationDate":"Third"})
# Replace Na values                                  
dataset = dataset.fillna(0)   
```

I will work with the South West's vaccination data.
```{r DataRegions, echo=FALSE} 
knitr::kable(py$dataset[1:5,])
```

```{python DataRegions_all_years, fig.align = "center", echo=FALSE}
plt.figure(figsize=(20,20))
sns.heatmap(data=
            dataset.sort_index())
```
As we can see, there are waves. So, the count of jabs depends on dates.

Let's get features:
1) Year
2) Month
3) Day
etc.

```{python DateFeatures, include=FALSE}
dataset['Year'] = dataset.index.year
dataset['Month'] = dataset.index.month
dataset['Day'] = dataset.index.day
dataset['DayOfYear'] = dataset.index.dayofyear
dataset['Weekday'] = dataset.index.weekday
dataset['Quarter'] = dataset.index.quarter
dataset['IsMonthStart'] = dataset.index.is_month_start
dataset['IsMonthEnd'] = dataset.index.is_month_end
```

```{r DataRegions_features, echo=FALSE} 
knitr::kable(py$dataset[1:5,])
```
\newpage
## Step 1: Explore the dataset

### Weekdays
As you remember, I have a question.
```{r ref0, ref.label='q2', render=pander::pander, echo=FALSE}
```

Let's answer.
```{r, echo=FALSE}
dataset_weekdays <- 
  py$dataset %>%
  group_by(Weekday)%>%
  summarise(across(c("First", "Second", "Third"), ~ mean(.x, na.rm = TRUE)))

dataset_weekdays$Weekday <- factor(dataset_weekdays$Weekday, labels = c('Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday'))

dataset_weekdays_long <-
  melt(dataset_weekdays, id.vars = c("Weekday")
                       , measure.vars = c("First", "Second", "Third")
                       , variable.name = "Dose"
                       , value.name = "Count"
                    )

ggplot(data = dataset_weekdays_long, 
       aes(x=Weekday, 
           y=Count,
           fill=Count
           )
         ) +
  geom_col(position = "dodge") +
  geom_vline(xintercept = "Saturday", color = "red") +
  facet_grid(Dose ~ .)
```

So, most of South West's people prefer to get a jab on Saturdays.

### Missing values
Calculate a count of dates in the dataset.
```{python, echo=FALSE}
len(dataset.index)
```
Calculate a count of dates between maximum and minimum dates.
```{python, echo=FALSE}
dates = pd.date_range(dataset.index.min(),dataset.index.max(),freq='d')
len(dates)
```
There are no missing dates.

## Step 2: Split sets, train a Machine Learning Model and Evaluate performance
```{r python_functions, include=FALSE}
# function for preparing sets
source_python('prepare_sets.py')
# function for training models
source_python('train_model.py')
```

Define necessary variables
```{python all_columns, include=FALSE}
feature_columns = ["Year", "Month", "Day", "DayOfYear", "Weekday", "Quarter", "IsMonthStart", "IsMonthEnd"]
```

Prepare sets and train models using parameters.
```{python first}
y_column = "First"
```

```{python train_all, echo=FALSE}
train_X, val_X, train_y, val_y = prepare_sets(dataset, feature_columns, y_column)

# DecisionTree
mae_dt, predictions_dt, model_dt = train_model(train_X, val_X, train_y, val_y, "DecisionTree", n_estimators=None)
# RandomForest
mae_rf, predictions_rf, model_rf = train_model(train_X, val_X, train_y, val_y, "RandomForest", n_estimators=500)

print("DecisionTree: ", 1 - mae_dt/dataset[y_column].mean())
print("RandomForest: ", 1 - mae_rf/dataset[y_column].mean())
```

Look at the tree
```{python tree_dt, echo=FALSE, fig.align = "center"}
plt.figure(figsize=(60, 40))
# feature_columns is defined above
tree.plot_tree(model_dt, max_depth=2, feature_names=feature_columns)
```

```{python tree_rf, echo=FALSE, fig.align = "center"}
plt.figure(figsize=(60,40))
# feature_columns is defined above
tree.plot_tree(model_rf.estimators_[0], max_depth=2, feature_names=feature_columns)
```

```{python plot_all, echo=FALSE, fig.align = "center"}
plt.figure(figsize=(25,15))
sns.set_style("darkgrid")
plt.title('{} ({})'.format("Comparing", y_column))
# plot DecisionTree
sns.lineplot(data=predictions_dt, label='{} MAE:{}'.format("DecisionTree", round(mae_dt,0)))
# plot RandomForest
sns.lineplot(data=predictions_rf, label='{} MAE:{}'.format("RandomForest", round(mae_rf,0)))
# plot validation set
val_y.index=range(0,len(val_y))
sns.lineplot(data=val_y, label="Validation")
# add legend
plt.legend()
```

```{python my_columns, include=FALSE}
feature_columns = ["Weekday", "Year", "DayOfYear"]
```

```{python, echo=FALSE}
<<train_all>>
#<<tree_dt>>
#<<tree_rf>>
<<plot_all>>
```


Repeat for the Second
```{python second_train}
y_column = "Second"
```

```{python, echo=FALSE}
<<columns_all>>
<<train_all>>
#<<tree_dt>>
#<<tree_rf>>
<<plot_all>>
```

```{python, echo=FALSE}
<<columns_my>>
<<train_all>>
#<<tree_dt>>
#<<tree_rf>>
<<plot_all>>
```

Compare the score with the mean value of the column that we predicted.

A combination of the following features give us the best result:

- Weekday, 

- Year, 

- DayOfYear






